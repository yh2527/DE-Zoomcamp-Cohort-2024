{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e71458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/26 19:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/02/26 19:04:04 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2045c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 19:04:28--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240227T030428Z&X-Amz-Expires=300&X-Amz-Signature=68efc8906eb36d6214c7f6eb1304753c7bcf9d141949254a5a3b8449c8e949ab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-02-26 19:04:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240227T030428Z&X-Amz-Expires=300&X-Amz-Signature=68efc8906eb36d6214c7f6eb1304753c7bcf9d141949254a5a3b8449c8e949ab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  19.6MB/s    in 0.9s    \n",
      "\n",
      "2024-02-26 19:04:29 (19.6 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dbc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1110864\r\n",
      "-rw-r--r--  1 yh  staff    18M Dec  1  2022 fhv_tripdata_2019-10.csv.gz\r\n",
      "-rw-r--r--  1 yh  staff   524M Jun 29  2022 fhvhv_tripdata_2019-10.parquet\r\n",
      "-rw-r--r--  1 yh  staff   9.2K Feb 26 00:07 spark-FHV-10-2019.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4fefbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62958 fhv_tripdata_2019-10.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120a424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True).csv(\"fhv_tripdata_2019-10.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1593bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime='2019-10-01 00:23:00', dropOff_datetime='2019-10-01 00:35:00', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime='2019-10-01 00:11:29', dropOff_datetime='2019-10-01 00:13:22', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00014', pickup_datetime='2019-10-01 00:11:43', dropOff_datetime='2019-10-01 00:37:20', PUlocationID='264', DOlocationID='264', SR_Flag=None, Affiliated_base_number='B00014')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555b89ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fe5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba88745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4baceab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1456edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e369e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "041604f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce766221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 86784\r\n",
      "-rw-r--r--  1 yh  staff     0B Feb 26 19:15 _SUCCESS\r\n",
      "-rw-r--r--  1 yh  staff   6.3M Feb 26 19:15 part-00000-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n",
      "-rw-r--r--  1 yh  staff   6.4M Feb 26 19:15 part-00001-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n",
      "-rw-r--r--  1 yh  staff   6.4M Feb 26 19:15 part-00002-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n",
      "-rw-r--r--  1 yh  staff   6.3M Feb 26 19:15 part-00003-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n",
      "-rw-r--r--  1 yh  staff   6.4M Feb 26 19:15 part-00004-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n",
      "-rw-r--r--  1 yh  staff   6.4M Feb 26 19:15 part-00005-11ecb041-8234-4223-ab5d-0cb1501cfc4c-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./fhvhv/2019/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaefe60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"./fhvhv/2019/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b02b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f3c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897493"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750a6fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B01413', pickup_datetime=datetime.datetime(2019, 10, 3, 13, 56, 26), dropoff_datetime=datetime.datetime(2019, 10, 3, 14, 7, 38), PULocationID=144, DOLocationID=90, SR_Flag=None, Affiliated_base_number='B01413'),\n",
       " Row(dispatching_base_num='B02653', pickup_datetime=datetime.datetime(2019, 10, 11, 18, 52, 26), dropoff_datetime=datetime.datetime(2019, 10, 11, 18, 58, 21), PULocationID=264, DOLocationID=235, SR_Flag=None, Affiliated_base_number='B02653'),\n",
       " Row(dispatching_base_num='B02416', pickup_datetime=datetime.datetime(2019, 10, 1, 9, 29), dropoff_datetime=datetime.datetime(2019, 10, 1, 12, 19, 34), PULocationID=None, DOLocationID=None, SR_Flag=None, Affiliated_base_number='B02416')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f293e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acba3d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(f.to_date(df.pickup_datetime) == datetime.date(2019, 10, 15)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0882ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f486e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|max_diff_hours|\n",
      "+--------------+\n",
      "|      631152.5|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    select max(unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) / 3600 AS max_diff_hours\n",
    "    from df\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "051a26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 20:56:40--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240227T045641Z&X-Amz-Expires=300&X-Amz-Signature=275c22878d0619b152d8fbd1346f6cb19a88758e8762e9ae7c5ed083a67b6a95&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-02-26 20:56:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240227T045641Z&X-Amz-Expires=300&X-Amz-Signature=275c22878d0619b152d8fbd1346f6cb19a88758e8762e9ae7c5ed083a67b6a95&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-02-26 20:56:41 (28.3 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff73cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = spark.read.option(\"header\", True).csv(\"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d00aee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f3499d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone.createOrReplaceTempView(\"zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c43cdd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------+\n",
      "|PULocationID|       Zone|ride_count|\n",
      "+------------+-----------+----------+\n",
      "|           2|Jamaica Bay|         1|\n",
      "+------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    select df.PULocationID, zone.Zone, count(*) as ride_count\n",
    "    from df left join zone on df.PULocationID = zone.LocationID\n",
    "    group by 1,2\n",
    "    order by 3\n",
    "    limit 1\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc46a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
